{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMa1/UP8IaSwFbES7hdFx/l",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JGutierrez90/Tesis_Juan_EAFIT_2025/blob/main/Modelo_de_machine_learning_NS_STEM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#0. Cargar las librerías necesarias"
      ],
      "metadata": {
        "id": "rx10Dnhc0REn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "vL3RGNNR0TVD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cargar el DataFrame producto del notebook anterior\n",
        "cluster_df = pd.read_csv('df_cluster_27jun.csv')"
      ],
      "metadata": {
        "id": "zusxL5UW0tIZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1.Agrupamiento por Kmeans"
      ],
      "metadata": {
        "id": "V6bAEriY0XNF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Hacer el escalamiento de los datos.\n",
        "\n",
        "scaler = StandardScaler()\n",
        "scaled_data = scaler.fit_transform(cluster_df)"
      ],
      "metadata": {
        "id": "UwhTs7iI0Z_w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Utilizar la técnica del codo para sugerencias de cantidad de clusters óptimos\n",
        "\n",
        "inertia = []\n",
        "k_range = range(1, 11)\n",
        "\n",
        "for k in k_range:\n",
        "    kmeans = KMeans(n_clusters=k, random_state=42)\n",
        "    kmeans.fit(scaled_data)\n",
        "    inertia.append(kmeans.inertia_)\n",
        "\n",
        "plt.plot(k_range, inertia, marker='o')\n",
        "plt.xlabel('Número de clusters (k)')\n",
        "plt.ylabel('cantidad de experimentos')\n",
        "plt.title('Método del codo')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "KaFG0hR504uL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Aplicación del algoritmo K-means con la cantidad de grupos k\n",
        "\n",
        "k = 2\n",
        "kmeans = KMeans(n_clusters=k, random_state=42)\n",
        "cluster_df['GRUPO_kmeans'] = kmeans.fit_predict(scaled_data)\n",
        "cluster_df['GRUPO_kmeans']"
      ],
      "metadata": {
        "id": "4xPcLQuL07UN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualización con PCA\n",
        "\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "pca = PCA(n_components=2)\n",
        "Scaled_pca = pca.fit_transform(scaled_data)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.scatterplot(x=Scaled_pca[:, 0], y=Scaled_pca[:, 1], hue=cluster_df['GRUPO_kmeans'], palette='Set2')\n",
        "plt.title('Clusters por K-means con reducción PCA a 2D')\n",
        "plt.xlabel('Componente Principal 1')\n",
        "plt.ylabel('Componente Principal 2')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Nu2qtpRv1C4L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import silhouette_score, calinski_harabasz_score, davies_bouldin_score\n",
        "\n",
        "labels = cluster_df['GRUPO_kmeans']\n",
        "\n",
        "#Métricas a calcular\n",
        "sil_score = silhouette_score(scaled_data, labels)\n",
        "cal_score = calinski_harabasz_score(scaled_data, labels)\n",
        "dav_score = davies_bouldin_score(scaled_data, labels)\n",
        "\n",
        "#Los resultados a mostrar por pantalla\n",
        "print(f'Silhouette Score: {sil_score:.3f} (ideal >= 0.5)')\n",
        "print(f'Calinski-Harabasz Score: {cal_score:.3f} (ideal >= 0)')\n",
        "print(f'Davies-Bouldin Score: {dav_score:.3f} (ideal <= 0)')"
      ],
      "metadata": {
        "id": "6p7dtyh11KH0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Agrupamiento por DBSCAN"
      ],
      "metadata": {
        "id": "8sNmeFhP0as3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import DBSCAN\n",
        "\n",
        "#Para no usar el data frame del método Kmeans, se carga otro dataframe\n",
        "# con el fin de ser usado con DBSCAN\n",
        "cluster_db = pd.read_csv('df_cluster_27jun.csv')\n",
        "\n",
        "\n",
        "#Una vez más colocar en la misma escala a los datos\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(cluster_db)\n",
        "\n",
        "#Uso de la herramienta SKL para hacer el agrupamiento con DBSCAN\n",
        "dbscan = DBSCAN(eps=14, min_samples=5)\n",
        "labels = dbscan.fit_predict(X_scaled)\n",
        "\n",
        "#Al dataframe de cluster_dv añadir nueva variable que identifica al grupo\n",
        "#asignado a cada una de las muestras\n",
        "cluster_db['GRUPO_dbscan'] = labels\n",
        "\n",
        "#Evaluar número de grupos asignados por el algoritmo DBSCAN\n",
        "n_clusters = len(set(labels)) - (1 if -1 in labels else 0)\n",
        "\n",
        "#Evaluar el silhouette score -Esperando que haya más de un grupo-\n",
        "if n_clusters > 1:\n",
        "    sil_scoredb = silhouette_score(X_scaled, labels)\n",
        "    print(f\"número de clusters (NO ruido): {n_clusters}\")\n",
        "    print(f\"índice del slihouette: {sil_scoredb: .4f} (ideal >= 0.5)\")\n",
        "else:\n",
        "  print(\"DBSCAN detectó menos de 2 clusters, no se puede calcular el silhoutte score.\")"
      ],
      "metadata": {
        "id": "iKY5FddE0lTK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#VISUALIZACIÓN MEDIANTE REDUCCIÓN DE DIMENSIONES PARA DESCUBRIR LO HECHO POR DBSCAN\n",
        "\n",
        "#Reducción a dos dimensiones para poder hacer la gráfica en plano coordenado.\n",
        "\n",
        "pca = PCA(n_components=2)\n",
        "X_pca = pca.fit_transform(X_scaled)\n",
        "\n",
        "#No escribir sobre los datos origniales al graficar\n",
        "df_graf = pd.DataFrame(X_pca, columns=['PCA1', 'PCA2'])\n",
        "df_graf['Cluster'] = cluster_db['GRUPO_dbscan'].astype(str) # Convertir a string para mostrar '-1' como ruido\n",
        "\n",
        "#Graficar\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.scatterplot(x='PCA1', y='PCA2', hue='Cluster', data=df_graf, palette='tab10', s=60, edgecolor='black', alpha=0.7)\n",
        "plt.title('Clusters por DBSCAN con reducción PCA a 2D')\n",
        "plt.xlabel('Componente Principal 1')\n",
        "plt.ylabel('Componente Principal 2')\n",
        "plt.legend(title='Cluster')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "wboOTn2I1QGe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Gráfico K-distance  para elegir mejores hiperparámetros.\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "import numpy as np\n",
        "\n",
        "min_samples = 5  # Puedes ajustar este valor\n",
        "neighbors = NearestNeighbors(n_neighbors=min_samples)\n",
        "neighbors_fit = neighbors.fit(X_scaled)\n",
        "distances, indices = neighbors_fit.kneighbors(X_scaled)\n",
        "\n",
        "# Distancias al k-ésimo vecino más cercano (posición -1)\n",
        "k_distances = np.sort(distances[:, -1])\n",
        "\n",
        "# Gráfico\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.plot(k_distances)\n",
        "plt.xlabel(\"Puntos ordenados\")\n",
        "plt.ylabel(f\"Distancia al {min_samples}º vecino más cercano\")\n",
        "plt.title(\"Gráfico de distancia k-vecinos para DBSCAN\")\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "GPeCd2cn1Vto"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "V_QbuJ0U0lzs"
      }
    }
  ]
}